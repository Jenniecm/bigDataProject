[2024-02-03T10:40:45.435+0100] {taskinstance.py:1957} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: jeniferhdfs.popular_movies_task scheduled__2024-02-02T00:00:00+00:00 [queued]>
[2024-02-03T10:40:45.464+0100] {taskinstance.py:1957} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: jeniferhdfs.popular_movies_task scheduled__2024-02-02T00:00:00+00:00 [queued]>
[2024-02-03T10:40:45.464+0100] {taskinstance.py:2171} INFO - Starting attempt 1 of 6
[2024-02-03T10:40:45.563+0100] {taskinstance.py:2192} INFO - Executing <Task(PythonOperator): popular_movies_task> on 2024-02-02 00:00:00+00:00
[2024-02-03T10:40:45.573+0100] {standard_task_runner.py:60} INFO - Started process 31906 to run task
[2024-02-03T10:40:45.601+0100] {standard_task_runner.py:87} INFO - Running: ['airflow', 'tasks', 'run', 'jeniferhdfs', 'popular_movies_task', 'scheduled__2024-02-02T00:00:00+00:00', '--job-id', '145', '--raw', '--subdir', 'DAGS_FOLDER/hdfsDag.py', '--cfg-path', '/tmp/tmp0evjhxme']
[2024-02-03T10:40:45.609+0100] {standard_task_runner.py:88} INFO - Job 145: Subtask popular_movies_task
[2024-02-03T10:40:46.628+0100] {task_command.py:423} INFO - Running <TaskInstance: jeniferhdfs.popular_movies_task scheduled__2024-02-02T00:00:00+00:00 [running]> on host ubuntu.ubuntu.virtualbox.org
[2024-02-03T10:40:47.427+0100] {taskinstance.py:2481} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='jenifer' AIRFLOW_CTX_DAG_ID='jeniferhdfs' AIRFLOW_CTX_TASK_ID='popular_movies_task' AIRFLOW_CTX_EXECUTION_DATE='2024-02-02T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-02-02T00:00:00+00:00'
[2024-02-03T10:40:47.457+0100] {logging_mixin.py:188} INFO - ***************************{'conf': <airflow.configuration.AirflowConfigParser object at 0x7f7d8b1989d0>, 'dag': <DAG: jeniferhdfs>, 'dag_run': <DagRun jeniferhdfs @ 2024-02-02 00:00:00+00:00: scheduled__2024-02-02T00:00:00+00:00, state:running, queued_at: 2024-02-03 09:40:29.732218+00:00. externally triggered: False>, 'data_interval_end': DateTime(2024, 2, 3, 0, 0, 0, tzinfo=Timezone('UTC')), 'data_interval_start': DateTime(2024, 2, 2, 0, 0, 0, tzinfo=Timezone('UTC')), 'ds': '2024-02-02', 'ds_nodash': '20240202', 'execution_date': <Proxy at 0x7f7d6e192a40 with factory functools.partial(<function lazy_mapping_from_context.<locals>._deprecated_proxy_factory at 0x7f7d6dfee7a0>, 'execution_date', DateTime(2024, 2, 2, 0, 0, 0, tzinfo=Timezone('UTC')))>, 'expanded_ti_count': None, 'inlets': [], 'logical_date': DateTime(2024, 2, 2, 0, 0, 0, tzinfo=Timezone('UTC')), 'macros': <module 'airflow.macros' from '/home/ubuntu/.local/lib/python3.10/site-packages/airflow/macros/__init__.py'>, 'next_ds': <Proxy at 0x7f7d85206b40 with factory functools.partial(<function lazy_mapping_from_context.<locals>._deprecated_proxy_factory at 0x7f7d6dfee7a0>, 'next_ds', '2024-02-03')>, 'next_ds_nodash': <Proxy at 0x7f7d6e044340 with factory functools.partial(<function lazy_mapping_from_context.<locals>._deprecated_proxy_factory at 0x7f7d6dfee7a0>, 'next_ds_nodash', '20240203')>, 'next_execution_date': <Proxy at 0x7f7d6e152d80 with factory functools.partial(<function lazy_mapping_from_context.<locals>._deprecated_proxy_factory at 0x7f7d6dfee7a0>, 'next_execution_date', DateTime(2024, 2, 3, 0, 0, 0, tzinfo=Timezone('UTC')))>, 'outlets': [], 'params': {}, 'prev_data_interval_start_success': None, 'prev_data_interval_end_success': None, 'prev_ds': <Proxy at 0x7f7d6e06fd40 with factory functools.partial(<function lazy_mapping_from_context.<locals>._deprecated_proxy_factory at 0x7f7d6dfee7a0>, 'prev_ds', '2024-02-01')>, 'prev_ds_nodash': <Proxy at 0x7f7d6def21c0 with factory functools.partial(<function lazy_mapping_from_context.<locals>._deprecated_proxy_factory at 0x7f7d6dfee7a0>, 'prev_ds_nodash', '20240201')>, 'prev_execution_date': <Proxy at 0x7f7d6def2ac0 with factory functools.partial(<function lazy_mapping_from_context.<locals>._deprecated_proxy_factory at 0x7f7d6dfee7a0>, 'prev_execution_date', DateTime(2024, 2, 1, 0, 0, 0, tzinfo=Timezone('UTC')))>, 'prev_execution_date_success': <Proxy at 0x7f7d6def2b00 with factory functools.partial(<function lazy_mapping_from_context.<locals>._deprecated_proxy_factory at 0x7f7d6dfee7a0>, 'prev_execution_date_success', None)>, 'prev_start_date_success': None, 'prev_end_date_success': None, 'run_id': 'scheduled__2024-02-02T00:00:00+00:00', 'task': <Task(PythonOperator): popular_movies_task>, 'task_instance': <TaskInstance: jeniferhdfs.popular_movies_task scheduled__2024-02-02T00:00:00+00:00 [running]>, 'task_instance_key_str': 'jeniferhdfs__popular_movies_task__20240202', 'test_mode': False, 'ti': <TaskInstance: jeniferhdfs.popular_movies_task scheduled__2024-02-02T00:00:00+00:00 [running]>, 'tomorrow_ds': <Proxy at 0x7f7d6def2b40 with factory functools.partial(<function lazy_mapping_from_context.<locals>._deprecated_proxy_factory at 0x7f7d6dfee7a0>, 'tomorrow_ds', '2024-02-03')>, 'tomorrow_ds_nodash': <Proxy at 0x7f7d6def2b80 with factory functools.partial(<function lazy_mapping_from_context.<locals>._deprecated_proxy_factory at 0x7f7d6dfee7a0>, 'tomorrow_ds_nodash', '20240203')>, 'triggering_dataset_events': <Proxy at 0x7f7d6e0a3e00 with factory <function _get_template_context.<locals>.get_triggering_events at 0x7f7d6e0a4670>>, 'ts': '2024-02-02T00:00:00+00:00', 'ts_nodash': '20240202T000000', 'ts_nodash_with_tz': '20240202T000000+0000', 'var': {'json': None, 'value': None}, 'conn': None, 'yesterday_ds': <Proxy at 0x7f7d6def2bc0 with factory functools.partial(<function lazy_mapping_from_context.<locals>._deprecated_proxy_factory at 0x7f7d6dfee7a0>, 'yesterday_ds', '2024-02-01')>, 'yesterday_ds_nodash': <Proxy at 0x7f7d6def2c00 with factory functools.partial(<function lazy_mapping_from_context.<locals>._deprecated_proxy_factory at 0x7f7d6dfee7a0>, 'yesterday_ds_nodash', '20240201')>, 'templates_dict': None}
[2024-02-03T10:43:28.954+0100] {client.py:192} INFO - Instantiated <InsecureClient(url='http://localhost:9870')>.
[2024-02-03T10:43:28.957+0100] {client.py:496} INFO - Writing to '/user/project/datalake/raw/2024-02-03/tmdb_popular_movies.json'.
[2024-02-03T10:43:58.210+0100] {logging_mixin.py:188} INFO - Data from pages 1 to 500 saved to HDFS successfully. Total records: 10000
[2024-02-03T10:43:58.233+0100] {python.py:201} INFO - Done. Returned value was: None
[2024-02-03T10:43:58.253+0100] {taskinstance.py:1138} INFO - Marking task as SUCCESS. dag_id=jeniferhdfs, task_id=popular_movies_task, execution_date=20240202T000000, start_date=20240203T094045, end_date=20240203T094358
[2024-02-03T10:43:58.454+0100] {local_task_job_runner.py:234} INFO - Task exited with return code 0
[2024-02-03T10:43:58.521+0100] {taskinstance.py:3281} INFO - 1 downstream tasks scheduled from follow-on schedule check
