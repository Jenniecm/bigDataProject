[2024-01-28T12:23:10.452+0100] {taskinstance.py:1957} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: jeniferhdfs.submit_spark_job manual__2024-01-28T11:21:57.207137+00:00 [queued]>
[2024-01-28T12:23:10.469+0100] {taskinstance.py:1957} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: jeniferhdfs.submit_spark_job manual__2024-01-28T11:21:57.207137+00:00 [queued]>
[2024-01-28T12:23:10.470+0100] {taskinstance.py:2171} INFO - Starting attempt 1 of 2
[2024-01-28T12:23:10.528+0100] {taskinstance.py:2192} INFO - Executing <Task(SparkSubmitOperator): submit_spark_job> on 2024-01-28 11:21:57.207137+00:00
[2024-01-28T12:23:10.550+0100] {standard_task_runner.py:60} INFO - Started process 24094 to run task
[2024-01-28T12:23:10.558+0100] {standard_task_runner.py:87} INFO - Running: ['airflow', 'tasks', 'run', 'jeniferhdfs', 'submit_spark_job', 'manual__2024-01-28T11:21:57.207137+00:00', '--job-id', '72', '--raw', '--subdir', 'DAGS_FOLDER/hdfsDag.py', '--cfg-path', '/tmp/tmpmty9o5dr']
[2024-01-28T12:23:10.563+0100] {standard_task_runner.py:88} INFO - Job 72: Subtask submit_spark_job
[2024-01-28T12:23:10.728+0100] {task_command.py:423} INFO - Running <TaskInstance: jeniferhdfs.submit_spark_job manual__2024-01-28T11:21:57.207137+00:00 [running]> on host ubuntu.ubuntu.virtualbox.org
[2024-01-28T12:23:10.956+0100] {taskinstance.py:2481} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='jenifer' AIRFLOW_CTX_DAG_ID='jeniferhdfs' AIRFLOW_CTX_TASK_ID='submit_spark_job' AIRFLOW_CTX_EXECUTION_DATE='2024-01-28T11:21:57.207137+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2024-01-28T11:21:57.207137+00:00'
[2024-01-28T12:23:10.982+0100] {base.py:83} INFO - Using connection ID 'spark_default' for task execution.
[2024-01-28T12:23:10.985+0100] {spark_submit.py:401} INFO - Spark-Submit cmd: spark-submit --master yarn --conf spark.master=local[*] --conf spark.yarn.conf.dir=/usr/local/hadoop/etc/hadoop --name your_spark_job --class main.scala.mnm.MnMcount --queue root.default hdfs://localhost:9000/user/project/datalake/main-scala-mnm_2.12-1.0.jar
[2024-01-28T12:23:30.765+0100] {spark_submit.py:571} INFO - 24/01/28 12:23:30 WARN Utils: Your hostname, ubuntu resolves to a loopback address: 127.0.1.1; using 10.0.2.15 instead (on interface enp0s3)
[2024-01-28T12:23:30.834+0100] {spark_submit.py:571} INFO - 24/01/28 12:23:30 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address
[2024-01-28T12:23:35.105+0100] {spark_submit.py:571} INFO - 24/01/28 12:23:35 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[2024-01-28T12:23:44.270+0100] {spark_submit.py:571} INFO - 24/01/28 12:23:44 INFO SparkContext: Running Spark version 3.3.4
[2024-01-28T12:23:44.611+0100] {spark_submit.py:571} INFO - 24/01/28 12:23:44 INFO ResourceUtils: ==============================================================
[2024-01-28T12:23:44.619+0100] {spark_submit.py:571} INFO - 24/01/28 12:23:44 INFO ResourceUtils: No custom resources configured for spark.driver.
[2024-01-28T12:23:44.621+0100] {spark_submit.py:571} INFO - 24/01/28 12:23:44 INFO ResourceUtils: ==============================================================
[2024-01-28T12:23:44.638+0100] {spark_submit.py:571} INFO - 24/01/28 12:23:44 INFO SparkContext: Submitted application: MnMCount
[2024-01-28T12:23:45.102+0100] {spark_submit.py:571} INFO - 24/01/28 12:23:45 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
[2024-01-28T12:23:45.219+0100] {spark_submit.py:571} INFO - 24/01/28 12:23:45 INFO ResourceProfile: Limiting resource is cpus at 1 tasks per executor
[2024-01-28T12:23:45.231+0100] {spark_submit.py:571} INFO - 24/01/28 12:23:45 INFO ResourceProfileManager: Added ResourceProfile id: 0
[2024-01-28T12:23:45.756+0100] {spark_submit.py:571} INFO - 24/01/28 12:23:45 INFO SecurityManager: Changing view acls to: ubuntu
[2024-01-28T12:23:45.760+0100] {spark_submit.py:571} INFO - 24/01/28 12:23:45 INFO SecurityManager: Changing modify acls to: ubuntu
[2024-01-28T12:23:45.763+0100] {spark_submit.py:571} INFO - 24/01/28 12:23:45 INFO SecurityManager: Changing view acls groups to:
[2024-01-28T12:23:45.766+0100] {spark_submit.py:571} INFO - 24/01/28 12:23:45 INFO SecurityManager: Changing modify acls groups to:
[2024-01-28T12:23:45.771+0100] {spark_submit.py:571} INFO - 24/01/28 12:23:45 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(ubuntu); groups with view permissions: Set(); users  with modify permissions: Set(ubuntu); groups with modify permissions: Set()
[2024-01-28T12:23:47.935+0100] {spark_submit.py:571} INFO - 24/01/28 12:23:47 INFO Utils: Successfully started service 'sparkDriver' on port 34315.
[2024-01-28T12:23:48.590+0100] {spark_submit.py:571} INFO - 24/01/28 12:23:48 INFO SparkEnv: Registering MapOutputTracker
[2024-01-28T12:23:49.178+0100] {spark_submit.py:571} INFO - 24/01/28 12:23:49 INFO SparkEnv: Registering BlockManagerMaster
[2024-01-28T12:23:49.440+0100] {spark_submit.py:571} INFO - 24/01/28 12:23:49 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
[2024-01-28T12:23:49.442+0100] {spark_submit.py:571} INFO - 24/01/28 12:23:49 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
[2024-01-28T12:23:49.697+0100] {spark_submit.py:571} INFO - 24/01/28 12:23:49 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
[2024-01-28T12:23:49.852+0100] {spark_submit.py:571} INFO - 24/01/28 12:23:49 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-5bad1964-0df5-4797-9bc5-37d64fd3dc39
[2024-01-28T12:23:50.439+0100] {spark_submit.py:571} INFO - 24/01/28 12:23:50 INFO MemoryStore: MemoryStore started with capacity 434.4 MiB
[2024-01-28T12:23:51.036+0100] {spark_submit.py:571} INFO - 24/01/28 12:23:51 INFO SparkEnv: Registering OutputCommitCoordinator
[2024-01-28T12:23:53.081+0100] {spark_submit.py:571} INFO - 24/01/28 12:23:53 INFO Utils: Successfully started service 'SparkUI' on port 4040.
[2024-01-28T12:23:53.494+0100] {spark_submit.py:571} INFO - 24/01/28 12:23:53 INFO SparkContext: Added JAR hdfs://localhost:9000/user/project/datalake/main-scala-mnm_2.12-1.0.jar at hdfs://localhost:9000/user/project/datalake/main-scala-mnm_2.12-1.0.jar with timestamp 1706441024189
[2024-01-28T12:23:55.005+0100] {spark_submit.py:571} INFO - 24/01/28 12:23:54 INFO DefaultNoHARMFailoverProxyProvider: Connecting to ResourceManager at /0.0.0.0:8032
[2024-01-28T12:23:57.082+0100] {spark_submit.py:571} INFO - 24/01/28 12:23:57 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-28T12:23:58.084+0100] {spark_submit.py:571} INFO - 24/01/28 12:23:58 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-28T12:23:59.090+0100] {spark_submit.py:571} INFO - 24/01/28 12:23:59 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-28T12:24:00.092+0100] {spark_submit.py:571} INFO - 24/01/28 12:24:00 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-28T12:24:01.102+0100] {spark_submit.py:571} INFO - 24/01/28 12:24:01 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-28T12:24:02.111+0100] {spark_submit.py:571} INFO - 24/01/28 12:24:02 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-28T12:24:03.112+0100] {spark_submit.py:571} INFO - 24/01/28 12:24:03 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-28T12:24:04.120+0100] {spark_submit.py:571} INFO - 24/01/28 12:24:04 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-28T12:24:05.136+0100] {spark_submit.py:571} INFO - 24/01/28 12:24:05 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-28T12:24:06.148+0100] {spark_submit.py:571} INFO - 24/01/28 12:24:06 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-28T12:24:07.246+0100] {spark_submit.py:571} INFO - 24/01/28 12:24:07 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-28T12:24:08.255+0100] {spark_submit.py:571} INFO - 24/01/28 12:24:08 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-28T12:24:09.265+0100] {spark_submit.py:571} INFO - 24/01/28 12:24:09 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-28T12:24:10.275+0100] {spark_submit.py:571} INFO - 24/01/28 12:24:10 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-28T12:24:11.279+0100] {spark_submit.py:571} INFO - 24/01/28 12:24:11 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-28T12:24:12.291+0100] {spark_submit.py:571} INFO - 24/01/28 12:24:12 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-28T12:24:13.298+0100] {spark_submit.py:571} INFO - 24/01/28 12:24:13 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-28T12:24:14.304+0100] {spark_submit.py:571} INFO - 24/01/28 12:24:14 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-28T12:24:15.310+0100] {spark_submit.py:571} INFO - 24/01/28 12:24:15 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-28T12:24:16.323+0100] {spark_submit.py:571} INFO - 24/01/28 12:24:16 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-28T12:24:16.325+0100] {spark_submit.py:571} INFO - 24/01/28 12:24:16 INFO RetryInvocationHandler: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking ApplicationClientProtocolPBClientImpl.getNewApplication over null after 1 failover attempts. Trying to failover after sleeping for 31048ms.
[2024-01-28T12:24:48.378+0100] {spark_submit.py:571} INFO - 24/01/28 12:24:48 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-28T12:24:49.380+0100] {spark_submit.py:571} INFO - 24/01/28 12:24:49 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-28T12:24:50.383+0100] {spark_submit.py:571} INFO - 24/01/28 12:24:50 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-28T12:24:51.385+0100] {spark_submit.py:571} INFO - 24/01/28 12:24:51 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-28T12:24:52.386+0100] {spark_submit.py:571} INFO - 24/01/28 12:24:52 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-28T12:24:53.389+0100] {spark_submit.py:571} INFO - 24/01/28 12:24:53 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-28T12:24:54.391+0100] {spark_submit.py:571} INFO - 24/01/28 12:24:54 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-28T12:24:55.396+0100] {spark_submit.py:571} INFO - 24/01/28 12:24:55 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-28T12:24:56.405+0100] {spark_submit.py:571} INFO - 24/01/28 12:24:56 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-28T12:24:57.416+0100] {spark_submit.py:571} INFO - 24/01/28 12:24:57 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-28T12:24:57.449+0100] {spark_submit.py:571} INFO - 24/01/28 12:24:57 INFO RetryInvocationHandler: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking ApplicationClientProtocolPBClientImpl.getNewApplication over null after 2 failover attempts. Trying to failover after sleeping for 34594ms.
[2024-01-28T12:25:33.049+0100] {spark_submit.py:571} INFO - 24/01/28 12:25:33 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-28T12:25:34.066+0100] {spark_submit.py:571} INFO - 24/01/28 12:25:34 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-28T12:25:35.079+0100] {spark_submit.py:571} INFO - 24/01/28 12:25:35 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-28T12:25:36.100+0100] {spark_submit.py:571} INFO - 24/01/28 12:25:36 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-28T12:25:37.104+0100] {spark_submit.py:571} INFO - 24/01/28 12:25:37 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-28T12:25:38.109+0100] {spark_submit.py:571} INFO - 24/01/28 12:25:38 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-28T12:25:39.114+0100] {spark_submit.py:571} INFO - 24/01/28 12:25:39 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-28T12:25:40.118+0100] {spark_submit.py:571} INFO - 24/01/28 12:25:40 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-28T12:25:41.121+0100] {spark_submit.py:571} INFO - 24/01/28 12:25:41 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-28T12:25:42.124+0100] {spark_submit.py:571} INFO - 24/01/28 12:25:42 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-28T12:25:42.129+0100] {spark_submit.py:571} INFO - 24/01/28 12:25:42 INFO RetryInvocationHandler: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking ApplicationClientProtocolPBClientImpl.getNewApplication over null after 3 failover attempts. Trying to failover after sleeping for 42219ms.
[2024-01-28T12:26:25.362+0100] {spark_submit.py:571} INFO - 24/01/28 12:26:25 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-28T12:26:26.364+0100] {spark_submit.py:571} INFO - 24/01/28 12:26:26 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-28T12:26:27.367+0100] {spark_submit.py:571} INFO - 24/01/28 12:26:27 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-28T12:26:28.368+0100] {spark_submit.py:571} INFO - 24/01/28 12:26:28 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-28T12:26:29.382+0100] {spark_submit.py:571} INFO - 24/01/28 12:26:29 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-28T12:26:30.394+0100] {spark_submit.py:571} INFO - 24/01/28 12:26:30 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-28T12:26:31.396+0100] {spark_submit.py:571} INFO - 24/01/28 12:26:31 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-28T12:26:32.403+0100] {spark_submit.py:571} INFO - 24/01/28 12:26:32 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-28T12:26:33.422+0100] {spark_submit.py:571} INFO - 24/01/28 12:26:33 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-28T12:26:34.424+0100] {spark_submit.py:571} INFO - 24/01/28 12:26:34 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-28T12:26:34.430+0100] {spark_submit.py:571} INFO - 24/01/28 12:26:34 INFO RetryInvocationHandler: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking ApplicationClientProtocolPBClientImpl.getNewApplication over null after 4 failover attempts. Trying to failover after sleeping for 16297ms.
[2024-01-28T12:26:51.737+0100] {spark_submit.py:571} INFO - 24/01/28 12:26:51 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-28T12:26:52.735+0100] {spark_submit.py:571} INFO - 24/01/28 12:26:52 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-28T12:26:53.738+0100] {spark_submit.py:571} INFO - 24/01/28 12:26:53 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-28T12:26:54.747+0100] {spark_submit.py:571} INFO - 24/01/28 12:26:54 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-28T12:26:55.744+0100] {spark_submit.py:571} INFO - 24/01/28 12:26:55 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-28T12:26:56.761+0100] {spark_submit.py:571} INFO - 24/01/28 12:26:56 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-28T12:26:57.772+0100] {spark_submit.py:571} INFO - 24/01/28 12:26:57 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-28T12:26:58.778+0100] {spark_submit.py:571} INFO - 24/01/28 12:26:58 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-28T12:26:59.783+0100] {spark_submit.py:571} INFO - 24/01/28 12:26:59 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-28T12:27:00.811+0100] {spark_submit.py:571} INFO - 24/01/28 12:27:00 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-28T12:27:00.812+0100] {spark_submit.py:571} INFO - 24/01/28 12:27:00 INFO RetryInvocationHandler: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking ApplicationClientProtocolPBClientImpl.getNewApplication over null after 5 failover attempts. Trying to failover after sleeping for 32172ms.
[2024-01-28T12:27:33.991+0100] {spark_submit.py:571} INFO - 24/01/28 12:27:33 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-28T12:27:35.007+0100] {spark_submit.py:571} INFO - 24/01/28 12:27:35 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-28T12:27:36.021+0100] {spark_submit.py:571} INFO - 24/01/28 12:27:36 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-28T12:27:37.029+0100] {spark_submit.py:571} INFO - 24/01/28 12:27:37 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-28T12:27:38.026+0100] {spark_submit.py:571} INFO - 24/01/28 12:27:38 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-28T12:27:39.045+0100] {spark_submit.py:571} INFO - 24/01/28 12:27:39 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-28T12:27:40.046+0100] {spark_submit.py:571} INFO - 24/01/28 12:27:40 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-28T12:27:41.067+0100] {spark_submit.py:571} INFO - 24/01/28 12:27:41 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-28T12:27:42.079+0100] {spark_submit.py:571} INFO - 24/01/28 12:27:42 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-28T12:27:43.082+0100] {spark_submit.py:571} INFO - 24/01/28 12:27:43 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-28T12:27:43.085+0100] {spark_submit.py:571} INFO - 24/01/28 12:27:43 INFO RetryInvocationHandler: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking ApplicationClientProtocolPBClientImpl.getNewApplication over null after 6 failover attempts. Trying to failover after sleeping for 25744ms.
[2024-01-28T12:28:09.848+0100] {spark_submit.py:571} INFO - 24/01/28 12:28:09 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-28T12:28:10.859+0100] {spark_submit.py:571} INFO - 24/01/28 12:28:10 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-28T12:28:11.871+0100] {spark_submit.py:571} INFO - 24/01/28 12:28:11 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-28T12:28:12.882+0100] {spark_submit.py:571} INFO - 24/01/28 12:28:12 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-28T12:28:13.923+0100] {spark_submit.py:571} INFO - 24/01/28 12:28:13 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-28T12:28:14.961+0100] {spark_submit.py:571} INFO - 24/01/28 12:28:14 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-28T12:28:15.973+0100] {spark_submit.py:571} INFO - 24/01/28 12:28:15 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-28T12:28:16.986+0100] {spark_submit.py:571} INFO - 24/01/28 12:28:16 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-28T12:28:17.993+0100] {spark_submit.py:571} INFO - 24/01/28 12:28:17 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-28T12:28:19.006+0100] {spark_submit.py:571} INFO - 24/01/28 12:28:19 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-28T12:28:19.014+0100] {spark_submit.py:571} INFO - 24/01/28 12:28:19 INFO RetryInvocationHandler: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking ApplicationClientProtocolPBClientImpl.getNewApplication over null after 7 failover attempts. Trying to failover after sleeping for 30618ms.
[2024-01-28T12:28:50.651+0100] {spark_submit.py:571} INFO - 24/01/28 12:28:50 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-28T12:28:51.678+0100] {spark_submit.py:571} INFO - 24/01/28 12:28:51 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-28T12:28:52.688+0100] {spark_submit.py:571} INFO - 24/01/28 12:28:52 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-28T12:28:53.694+0100] {spark_submit.py:571} INFO - 24/01/28 12:28:53 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-28T12:28:54.708+0100] {spark_submit.py:571} INFO - 24/01/28 12:28:54 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-28T12:28:55.720+0100] {spark_submit.py:571} INFO - 24/01/28 12:28:55 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-28T12:28:56.741+0100] {spark_submit.py:571} INFO - 24/01/28 12:28:56 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-28T12:28:57.761+0100] {spark_submit.py:571} INFO - 24/01/28 12:28:57 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-28T12:28:58.786+0100] {spark_submit.py:571} INFO - 24/01/28 12:28:58 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-28T12:28:59.797+0100] {spark_submit.py:571} INFO - 24/01/28 12:28:59 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-28T12:28:59.815+0100] {spark_submit.py:571} INFO - 24/01/28 12:28:59 INFO RetryInvocationHandler: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking ApplicationClientProtocolPBClientImpl.getNewApplication over null after 8 failover attempts. Trying to failover after sleeping for 21517ms.
[2024-01-28T12:29:22.365+0100] {spark_submit.py:571} INFO - 24/01/28 12:29:22 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-28T12:29:23.365+0100] {spark_submit.py:571} INFO - 24/01/28 12:29:23 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-28T12:29:24.379+0100] {spark_submit.py:571} INFO - 24/01/28 12:29:24 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-28T12:29:25.399+0100] {spark_submit.py:571} INFO - 24/01/28 12:29:25 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-28T12:29:26.402+0100] {spark_submit.py:571} INFO - 24/01/28 12:29:26 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-28T12:29:27.407+0100] {spark_submit.py:571} INFO - 24/01/28 12:29:27 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-28T12:29:28.417+0100] {spark_submit.py:571} INFO - 24/01/28 12:29:28 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-28T12:29:29.427+0100] {spark_submit.py:571} INFO - 24/01/28 12:29:29 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-28T12:29:30.428+0100] {spark_submit.py:571} INFO - 24/01/28 12:29:30 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-28T12:29:31.434+0100] {spark_submit.py:571} INFO - 24/01/28 12:29:31 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-28T12:29:31.475+0100] {spark_submit.py:571} INFO - 24/01/28 12:29:31 INFO RetryInvocationHandler: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking ApplicationClientProtocolPBClientImpl.getNewApplication over null after 9 failover attempts. Trying to failover after sleeping for 36897ms.
[2024-01-28T12:30:09.481+0100] {spark_submit.py:571} INFO - 24/01/28 12:30:09 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-28T12:30:10.471+0100] {spark_submit.py:571} INFO - 24/01/28 12:30:10 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-28T12:30:11.477+0100] {spark_submit.py:571} INFO - 24/01/28 12:30:11 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-28T12:30:12.479+0100] {spark_submit.py:571} INFO - 24/01/28 12:30:12 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-28T12:30:13.494+0100] {spark_submit.py:571} INFO - 24/01/28 12:30:13 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-28T12:30:14.498+0100] {spark_submit.py:571} INFO - 24/01/28 12:30:14 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-28T12:30:15.504+0100] {spark_submit.py:571} INFO - 24/01/28 12:30:15 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-28T12:30:16.506+0100] {spark_submit.py:571} INFO - 24/01/28 12:30:16 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-28T12:30:17.508+0100] {spark_submit.py:571} INFO - 24/01/28 12:30:17 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-28T12:30:18.516+0100] {spark_submit.py:571} INFO - 24/01/28 12:30:18 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-28T12:30:18.661+0100] {spark_submit.py:571} INFO - 24/01/28 12:30:18 INFO RetryInvocationHandler: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking ApplicationClientProtocolPBClientImpl.getNewApplication over null after 10 failover attempts. Trying to failover after sleeping for 15445ms.
[2024-01-28T12:30:35.226+0100] {spark_submit.py:571} INFO - 24/01/28 12:30:35 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-28T12:30:36.226+0100] {spark_submit.py:571} INFO - 24/01/28 12:30:36 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-28T12:30:37.228+0100] {spark_submit.py:571} INFO - 24/01/28 12:30:37 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-28T12:30:38.235+0100] {spark_submit.py:571} INFO - 24/01/28 12:30:38 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-28T12:30:39.329+0100] {spark_submit.py:571} INFO - 24/01/28 12:30:39 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-28T12:30:40.512+0100] {spark_submit.py:571} INFO - 24/01/28 12:30:40 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-28T12:30:41.514+0100] {spark_submit.py:571} INFO - 24/01/28 12:30:41 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-28T12:30:42.523+0100] {spark_submit.py:571} INFO - 24/01/28 12:30:42 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-28T12:30:43.534+0100] {spark_submit.py:571} INFO - 24/01/28 12:30:43 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-28T12:30:44.552+0100] {spark_submit.py:571} INFO - 24/01/28 12:30:44 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-28T12:30:44.575+0100] {spark_submit.py:571} INFO - 24/01/28 12:30:44 INFO RetryInvocationHandler: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking ApplicationClientProtocolPBClientImpl.getNewApplication over null after 11 failover attempts. Trying to failover after sleeping for 18375ms.
[2024-01-28T12:31:04.213+0100] {spark_submit.py:571} INFO - 24/01/28 12:31:04 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-28T12:31:05.209+0100] {spark_submit.py:571} INFO - 24/01/28 12:31:05 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-28T12:31:06.215+0100] {spark_submit.py:571} INFO - 24/01/28 12:31:06 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-28T12:31:07.216+0100] {spark_submit.py:571} INFO - 24/01/28 12:31:07 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-28T12:31:08.219+0100] {spark_submit.py:571} INFO - 24/01/28 12:31:08 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-28T12:31:09.224+0100] {spark_submit.py:571} INFO - 24/01/28 12:31:09 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-28T12:31:10.230+0100] {spark_submit.py:571} INFO - 24/01/28 12:31:10 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-28T12:31:11.228+0100] {spark_submit.py:571} INFO - 24/01/28 12:31:11 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-28T12:31:12.240+0100] {spark_submit.py:571} INFO - 24/01/28 12:31:12 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-28T12:31:13.246+0100] {spark_submit.py:571} INFO - 24/01/28 12:31:13 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-28T12:31:13.437+0100] {spark_submit.py:571} INFO - 24/01/28 12:31:13 INFO RetryInvocationHandler: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking ApplicationClientProtocolPBClientImpl.getNewApplication over null after 12 failover attempts. Trying to failover after sleeping for 31057ms.
[2024-01-28T12:31:45.814+0100] {spark_submit.py:571} INFO - 24/01/28 12:31:45 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-28T12:31:46.830+0100] {spark_submit.py:571} INFO - 24/01/28 12:31:46 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-28T12:31:47.849+0100] {spark_submit.py:571} INFO - 24/01/28 12:31:47 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-28T12:31:48.854+0100] {spark_submit.py:571} INFO - 24/01/28 12:31:48 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-28T12:31:49.857+0100] {spark_submit.py:571} INFO - 24/01/28 12:31:49 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-28T12:31:50.865+0100] {spark_submit.py:571} INFO - 24/01/28 12:31:50 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-28T12:31:51.886+0100] {spark_submit.py:571} INFO - 24/01/28 12:31:51 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-28T12:31:52.915+0100] {spark_submit.py:571} INFO - 24/01/28 12:31:52 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-28T12:31:53.923+0100] {spark_submit.py:571} INFO - 24/01/28 12:31:53 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-28T12:31:54.948+0100] {spark_submit.py:571} INFO - 24/01/28 12:31:54 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-28T12:31:55.125+0100] {spark_submit.py:571} INFO - 24/01/28 12:31:55 INFO RetryInvocationHandler: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking ApplicationClientProtocolPBClientImpl.getNewApplication over null after 13 failover attempts. Trying to failover after sleeping for 24241ms.
[2024-01-28T12:32:20.524+0100] {spark_submit.py:571} INFO - 24/01/28 12:32:20 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-28T12:32:21.506+0100] {spark_submit.py:571} INFO - 24/01/28 12:32:21 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-28T12:32:22.508+0100] {spark_submit.py:571} INFO - 24/01/28 12:32:22 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-28T12:32:23.523+0100] {spark_submit.py:571} INFO - 24/01/28 12:32:23 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-28T12:32:24.534+0100] {spark_submit.py:571} INFO - 24/01/28 12:32:24 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-28T12:32:25.561+0100] {spark_submit.py:571} INFO - 24/01/28 12:32:25 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-28T12:32:26.565+0100] {spark_submit.py:571} INFO - 24/01/28 12:32:26 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-28T12:32:27.566+0100] {spark_submit.py:571} INFO - 24/01/28 12:32:27 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-28T12:32:28.569+0100] {spark_submit.py:571} INFO - 24/01/28 12:32:28 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-28T12:32:29.571+0100] {spark_submit.py:571} INFO - 24/01/28 12:32:29 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-28T12:32:29.731+0100] {spark_submit.py:571} INFO - 24/01/28 12:32:29 INFO RetryInvocationHandler: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking ApplicationClientProtocolPBClientImpl.getNewApplication over null after 14 failover attempts. Trying to failover after sleeping for 30956ms.
[2024-01-28T12:33:02.137+0100] {spark_submit.py:571} INFO - 24/01/28 12:33:02 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-28T12:33:03.128+0100] {spark_submit.py:571} INFO - 24/01/28 12:33:03 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-28T12:33:04.134+0100] {spark_submit.py:571} INFO - 24/01/28 12:33:04 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-28T12:33:05.146+0100] {spark_submit.py:571} INFO - 24/01/28 12:33:05 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-28T12:33:06.152+0100] {spark_submit.py:571} INFO - 24/01/28 12:33:06 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-28T12:33:07.338+0100] {spark_submit.py:571} INFO - 24/01/28 12:33:07 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-28T12:33:08.340+0100] {spark_submit.py:571} INFO - 24/01/28 12:33:08 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-28T12:33:09.348+0100] {spark_submit.py:571} INFO - 24/01/28 12:33:09 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-28T12:33:10.358+0100] {spark_submit.py:571} INFO - 24/01/28 12:33:10 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-28T12:33:11.471+0100] {spark_submit.py:571} INFO - 24/01/28 12:33:11 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-28T12:33:11.676+0100] {spark_submit.py:571} INFO - 24/01/28 12:33:11 INFO RetryInvocationHandler: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking ApplicationClientProtocolPBClientImpl.getNewApplication over null after 15 failover attempts. Trying to failover after sleeping for 36463ms.
[2024-01-28T12:33:49.532+0100] {spark_submit.py:571} INFO - 24/01/28 12:33:49 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-28T12:33:51.246+0100] {spark_submit.py:571} INFO - 24/01/28 12:33:51 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-28T12:33:52.667+0100] {spark_submit.py:571} INFO - 24/01/28 12:33:52 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-28T12:33:53.820+0100] {spark_submit.py:571} INFO - 24/01/28 12:33:53 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-28T12:33:54.991+0100] {spark_submit.py:571} INFO - 24/01/28 12:33:54 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-28T12:33:56.118+0100] {spark_submit.py:571} INFO - 24/01/28 12:33:56 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-28T12:33:57.371+0100] {spark_submit.py:571} INFO - 24/01/28 12:33:57 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-28T12:33:58.417+0100] {spark_submit.py:571} INFO - 24/01/28 12:33:58 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-28T12:33:59.482+0100] {spark_submit.py:571} INFO - 24/01/28 12:33:59 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-28T12:34:00.668+0100] {spark_submit.py:571} INFO - 24/01/28 12:34:00 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-28T12:34:00.696+0100] {spark_submit.py:571} INFO - 24/01/28 12:34:00 INFO RetryInvocationHandler: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking ApplicationClientProtocolPBClientImpl.getNewApplication over null after 16 failover attempts. Trying to failover after sleeping for 25319ms.
[2024-01-28T12:34:27.099+0100] {spark_submit.py:571} INFO - 24/01/28 12:34:27 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-28T12:34:28.104+0100] {spark_submit.py:571} INFO - 24/01/28 12:34:28 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-28T12:34:29.110+0100] {spark_submit.py:571} INFO - 24/01/28 12:34:29 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-28T12:34:30.127+0100] {spark_submit.py:571} INFO - 24/01/28 12:34:30 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-28T12:34:31.131+0100] {spark_submit.py:571} INFO - 24/01/28 12:34:31 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-28T12:34:32.137+0100] {spark_submit.py:571} INFO - 24/01/28 12:34:32 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-28T12:34:33.140+0100] {spark_submit.py:571} INFO - 24/01/28 12:34:33 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-28T12:34:34.152+0100] {spark_submit.py:571} INFO - 24/01/28 12:34:34 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-28T12:34:35.157+0100] {spark_submit.py:571} INFO - 24/01/28 12:34:35 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-28T12:34:36.178+0100] {spark_submit.py:571} INFO - 24/01/28 12:34:36 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-28T12:34:36.367+0100] {spark_submit.py:571} INFO - 24/01/28 12:34:36 INFO RetryInvocationHandler: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking ApplicationClientProtocolPBClientImpl.getNewApplication over null after 17 failover attempts. Trying to failover after sleeping for 16677ms.
[2024-01-28T12:34:54.219+0100] {spark_submit.py:571} INFO - 24/01/28 12:34:54 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-28T12:34:55.245+0100] {spark_submit.py:571} INFO - 24/01/28 12:34:55 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-28T12:34:56.250+0100] {spark_submit.py:571} INFO - 24/01/28 12:34:56 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-28T12:34:57.258+0100] {spark_submit.py:571} INFO - 24/01/28 12:34:57 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-28T12:34:58.348+0100] {spark_submit.py:571} INFO - 24/01/28 12:34:58 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-28T12:34:59.525+0100] {spark_submit.py:571} INFO - 24/01/28 12:34:59 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-28T12:35:00.538+0100] {spark_submit.py:571} INFO - 24/01/28 12:35:00 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-28T12:35:01.542+0100] {spark_submit.py:571} INFO - 24/01/28 12:35:01 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-28T12:35:02.564+0100] {spark_submit.py:571} INFO - 24/01/28 12:35:02 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-28T12:35:03.567+0100] {spark_submit.py:571} INFO - 24/01/28 12:35:03 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-28T12:35:03.847+0100] {spark_submit.py:571} INFO - 24/01/28 12:35:03 INFO RetryInvocationHandler: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking ApplicationClientProtocolPBClientImpl.getNewApplication over null after 18 failover attempts. Trying to failover after sleeping for 33771ms.
[2024-01-28T12:35:38.941+0100] {spark_submit.py:571} INFO - 24/01/28 12:35:38 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-28T12:35:40.015+0100] {spark_submit.py:571} INFO - 24/01/28 12:35:40 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-28T12:35:41.081+0100] {spark_submit.py:571} INFO - 24/01/28 12:35:41 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-28T12:35:42.123+0100] {spark_submit.py:571} INFO - 24/01/28 12:35:42 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-28T12:35:43.124+0100] {spark_submit.py:571} INFO - 24/01/28 12:35:43 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-28T12:35:44.240+0100] {spark_submit.py:571} INFO - 24/01/28 12:35:44 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-28T12:35:45.254+0100] {spark_submit.py:571} INFO - 24/01/28 12:35:45 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-28T12:35:46.273+0100] {spark_submit.py:571} INFO - 24/01/28 12:35:46 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-28T12:35:47.292+0100] {spark_submit.py:571} INFO - 24/01/28 12:35:47 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-28T12:35:48.321+0100] {spark_submit.py:571} INFO - 24/01/28 12:35:48 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-28T12:35:49.025+0100] {spark_submit.py:571} INFO - 24/01/28 12:35:48 INFO RetryInvocationHandler: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking ApplicationClientProtocolPBClientImpl.getNewApplication over null after 19 failover attempts. Trying to failover after sleeping for 24305ms.
[2024-01-28T12:36:14.560+0100] {spark_submit.py:571} INFO - 24/01/28 12:36:14 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-28T12:36:15.561+0100] {spark_submit.py:571} INFO - 24/01/28 12:36:15 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-28T12:36:16.564+0100] {spark_submit.py:571} INFO - 24/01/28 12:36:16 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-28T12:36:17.596+0100] {spark_submit.py:571} INFO - 24/01/28 12:36:17 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-28T12:36:18.602+0100] {spark_submit.py:571} INFO - 24/01/28 12:36:18 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-28T12:36:19.603+0100] {spark_submit.py:571} INFO - 24/01/28 12:36:19 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-28T12:36:20.606+0100] {spark_submit.py:571} INFO - 24/01/28 12:36:20 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-28T12:36:21.614+0100] {spark_submit.py:571} INFO - 24/01/28 12:36:21 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-28T12:36:22.617+0100] {spark_submit.py:571} INFO - 24/01/28 12:36:22 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-28T12:36:23.619+0100] {spark_submit.py:571} INFO - 24/01/28 12:36:23 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-28T12:36:23.619+0100] {spark_submit.py:571} INFO - 24/01/28 12:36:23 INFO RetryInvocationHandler: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking ApplicationClientProtocolPBClientImpl.getNewApplication over null after 20 failover attempts. Trying to failover after sleeping for 16102ms.
[2024-01-28T12:36:40.764+0100] {spark_submit.py:571} INFO - 24/01/28 12:36:40 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-28T12:36:41.775+0100] {spark_submit.py:571} INFO - 24/01/28 12:36:41 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-28T12:36:42.775+0100] {spark_submit.py:571} INFO - 24/01/28 12:36:42 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-28T12:36:43.791+0100] {spark_submit.py:571} INFO - 24/01/28 12:36:43 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-28T12:36:44.793+0100] {spark_submit.py:571} INFO - 24/01/28 12:36:44 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-28T12:36:45.804+0100] {spark_submit.py:571} INFO - 24/01/28 12:36:45 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-28T12:36:46.807+0100] {spark_submit.py:571} INFO - 24/01/28 12:36:46 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-28T12:36:47.828+0100] {spark_submit.py:571} INFO - 24/01/28 12:36:47 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-28T12:36:48.845+0100] {spark_submit.py:571} INFO - 24/01/28 12:36:48 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-28T12:36:49.879+0100] {spark_submit.py:571} INFO - 24/01/28 12:36:49 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-28T12:36:49.881+0100] {spark_submit.py:571} INFO - 24/01/28 12:36:49 INFO RetryInvocationHandler: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking ApplicationClientProtocolPBClientImpl.getNewApplication over null after 21 failover attempts. Trying to failover after sleeping for 41828ms.
[2024-01-28T12:37:32.971+0100] {spark_submit.py:571} INFO - 24/01/28 12:37:32 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-28T12:37:33.984+0100] {spark_submit.py:571} INFO - 24/01/28 12:37:33 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-28T12:37:34.990+0100] {spark_submit.py:571} INFO - 24/01/28 12:37:34 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-28T12:37:35.997+0100] {spark_submit.py:571} INFO - 24/01/28 12:37:35 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-28T12:37:37.008+0100] {spark_submit.py:571} INFO - 24/01/28 12:37:37 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-28T12:37:38.012+0100] {spark_submit.py:571} INFO - 24/01/28 12:37:38 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-28T12:37:39.018+0100] {spark_submit.py:571} INFO - 24/01/28 12:37:39 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-28T12:37:40.040+0100] {spark_submit.py:571} INFO - 24/01/28 12:37:40 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-28T12:37:41.047+0100] {spark_submit.py:571} INFO - 24/01/28 12:37:41 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-28T12:37:42.049+0100] {spark_submit.py:571} INFO - 24/01/28 12:37:42 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-28T12:37:42.210+0100] {spark_submit.py:571} INFO - 24/01/28 12:37:42 INFO RetryInvocationHandler: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking ApplicationClientProtocolPBClientImpl.getNewApplication over null after 22 failover attempts. Trying to failover after sleeping for 18279ms.
[2024-01-28T12:38:01.878+0100] {spark_submit.py:571} INFO - 24/01/28 12:38:01 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-28T12:38:02.887+0100] {spark_submit.py:571} INFO - 24/01/28 12:38:02 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-28T12:38:03.906+0100] {spark_submit.py:571} INFO - 24/01/28 12:38:03 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-28T12:38:04.903+0100] {spark_submit.py:571} INFO - 24/01/28 12:38:04 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-28T12:38:05.914+0100] {spark_submit.py:571} INFO - 24/01/28 12:38:05 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-28T12:38:06.926+0100] {spark_submit.py:571} INFO - 24/01/28 12:38:06 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-28T12:38:07.929+0100] {spark_submit.py:571} INFO - 24/01/28 12:38:07 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-28T12:38:08.935+0100] {spark_submit.py:571} INFO - 24/01/28 12:38:08 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-28T12:38:09.938+0100] {spark_submit.py:571} INFO - 24/01/28 12:38:09 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-28T12:38:10.976+0100] {spark_submit.py:571} INFO - 24/01/28 12:38:10 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-28T12:38:11.131+0100] {spark_submit.py:571} INFO - 24/01/28 12:38:11 INFO RetryInvocationHandler: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking ApplicationClientProtocolPBClientImpl.getNewApplication over null after 23 failover attempts. Trying to failover after sleeping for 33002ms.
[2024-01-28T12:38:45.352+0100] {spark_submit.py:571} INFO - 24/01/28 12:38:45 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-28T12:38:46.412+0100] {spark_submit.py:571} INFO - 24/01/28 12:38:46 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-28T12:38:47.425+0100] {spark_submit.py:571} INFO - 24/01/28 12:38:47 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-28T12:38:48.434+0100] {spark_submit.py:571} INFO - 24/01/28 12:38:48 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-28T12:38:49.437+0100] {spark_submit.py:571} INFO - 24/01/28 12:38:49 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-28T12:38:50.471+0100] {spark_submit.py:571} INFO - 24/01/28 12:38:50 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-28T12:38:51.473+0100] {spark_submit.py:571} INFO - 24/01/28 12:38:51 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-28T12:38:52.474+0100] {spark_submit.py:571} INFO - 24/01/28 12:38:52 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-28T12:38:53.486+0100] {spark_submit.py:571} INFO - 24/01/28 12:38:53 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-28T12:38:54.491+0100] {spark_submit.py:571} INFO - 24/01/28 12:38:54 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-28T12:38:54.506+0100] {spark_submit.py:571} INFO - 24/01/28 12:38:54 INFO RetryInvocationHandler: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking ApplicationClientProtocolPBClientImpl.getNewApplication over null after 24 failover attempts. Trying to failover after sleeping for 18218ms.
[2024-01-28T12:39:13.803+0100] {spark_submit.py:571} INFO - 24/01/28 12:39:13 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-28T12:39:14.812+0100] {spark_submit.py:571} INFO - 24/01/28 12:39:14 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-28T12:39:15.813+0100] {spark_submit.py:571} INFO - 24/01/28 12:39:15 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-28T12:39:16.820+0100] {spark_submit.py:571} INFO - 24/01/28 12:39:16 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-28T12:39:17.827+0100] {spark_submit.py:571} INFO - 24/01/28 12:39:17 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-28T12:39:18.831+0100] {spark_submit.py:571} INFO - 24/01/28 12:39:18 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-28T12:39:19.836+0100] {spark_submit.py:571} INFO - 24/01/28 12:39:19 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-28T12:39:20.842+0100] {spark_submit.py:571} INFO - 24/01/28 12:39:20 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-28T12:39:21.873+0100] {spark_submit.py:571} INFO - 24/01/28 12:39:21 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-28T12:39:22.884+0100] {spark_submit.py:571} INFO - 24/01/28 12:39:22 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-28T12:39:22.915+0100] {spark_submit.py:571} INFO - 24/01/28 12:39:22 INFO RetryInvocationHandler: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking ApplicationClientProtocolPBClientImpl.getNewApplication over null after 25 failover attempts. Trying to failover after sleeping for 32886ms.
[2024-01-28T12:39:56.815+0100] {spark_submit.py:571} INFO - 24/01/28 12:39:56 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-28T12:39:57.823+0100] {spark_submit.py:571} INFO - 24/01/28 12:39:57 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-28T12:39:58.824+0100] {spark_submit.py:571} INFO - 24/01/28 12:39:58 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-28T12:39:59.871+0100] {spark_submit.py:571} INFO - 24/01/28 12:39:59 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-28T12:40:00.895+0100] {spark_submit.py:571} INFO - 24/01/28 12:40:00 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-28T12:40:01.898+0100] {spark_submit.py:571} INFO - 24/01/28 12:40:01 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-28T12:40:02.905+0100] {spark_submit.py:571} INFO - 24/01/28 12:40:02 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-28T12:40:03.912+0100] {spark_submit.py:571} INFO - 24/01/28 12:40:03 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-28T12:40:04.920+0100] {spark_submit.py:571} INFO - 24/01/28 12:40:04 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-28T12:40:05.923+0100] {spark_submit.py:571} INFO - 24/01/28 12:40:05 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-28T12:40:06.025+0100] {spark_submit.py:571} INFO - 24/01/28 12:40:06 INFO RetryInvocationHandler: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking ApplicationClientProtocolPBClientImpl.getNewApplication over null after 26 failover attempts. Trying to failover after sleeping for 35299ms.
[2024-01-28T12:40:42.603+0100] {spark_submit.py:571} INFO - 24/01/28 12:40:42 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-28T12:40:43.608+0100] {spark_submit.py:571} INFO - 24/01/28 12:40:43 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-28T12:40:44.624+0100] {spark_submit.py:571} INFO - 24/01/28 12:40:44 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-28T12:40:45.701+0100] {spark_submit.py:571} INFO - 24/01/28 12:40:45 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-28T12:40:46.703+0100] {spark_submit.py:571} INFO - 24/01/28 12:40:46 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-28T12:40:47.738+0100] {spark_submit.py:571} INFO - 24/01/28 12:40:47 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-28T12:40:48.751+0100] {spark_submit.py:571} INFO - 24/01/28 12:40:48 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-28T12:40:49.753+0100] {spark_submit.py:571} INFO - 24/01/28 12:40:49 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-28T12:40:50.817+0100] {spark_submit.py:571} INFO - 24/01/28 12:40:50 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-28T12:40:51.826+0100] {spark_submit.py:571} INFO - 24/01/28 12:40:51 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-28T12:40:52.015+0100] {spark_submit.py:571} INFO - 24/01/28 12:40:52 INFO RetryInvocationHandler: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking ApplicationClientProtocolPBClientImpl.getNewApplication over null after 27 failover attempts. Trying to failover after sleeping for 25120ms.
[2024-01-28T12:41:18.371+0100] {spark_submit.py:571} INFO - 24/01/28 12:41:18 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-28T12:41:19.379+0100] {spark_submit.py:571} INFO - 24/01/28 12:41:19 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-28T12:41:20.381+0100] {spark_submit.py:571} INFO - 24/01/28 12:41:20 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-28T12:41:21.438+0100] {spark_submit.py:571} INFO - 24/01/28 12:41:21 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-28T12:41:22.467+0100] {spark_submit.py:571} INFO - 24/01/28 12:41:22 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-28T12:41:23.587+0100] {spark_submit.py:571} INFO - 24/01/28 12:41:23 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-28T12:41:24.625+0100] {spark_submit.py:571} INFO - 24/01/28 12:41:24 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-28T12:41:25.652+0100] {spark_submit.py:571} INFO - 24/01/28 12:41:25 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-28T12:41:26.654+0100] {spark_submit.py:571} INFO - 24/01/28 12:41:26 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-28T12:41:27.677+0100] {spark_submit.py:571} INFO - 24/01/28 12:41:27 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-28T12:41:27.848+0100] {spark_submit.py:571} INFO - 24/01/28 12:41:27 INFO RetryInvocationHandler: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking ApplicationClientProtocolPBClientImpl.getNewApplication over null after 28 failover attempts. Trying to failover after sleeping for 16749ms.
[2024-01-28T12:41:45.761+0100] {spark_submit.py:571} INFO - 24/01/28 12:41:45 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-28T12:41:46.761+0100] {spark_submit.py:571} INFO - 24/01/28 12:41:46 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-28T12:41:47.781+0100] {spark_submit.py:571} INFO - 24/01/28 12:41:47 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-28T12:41:48.786+0100] {spark_submit.py:571} INFO - 24/01/28 12:41:48 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-28T12:41:49.788+0100] {spark_submit.py:571} INFO - 24/01/28 12:41:49 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-28T12:41:50.867+0100] {spark_submit.py:571} INFO - 24/01/28 12:41:50 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-28T12:41:51.870+0100] {spark_submit.py:571} INFO - 24/01/28 12:41:51 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-28T12:41:52.872+0100] {spark_submit.py:571} INFO - 24/01/28 12:41:52 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-28T12:41:53.875+0100] {spark_submit.py:571} INFO - 24/01/28 12:41:53 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-28T12:41:54.877+0100] {spark_submit.py:571} INFO - 24/01/28 12:41:54 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-28T12:41:54.956+0100] {spark_submit.py:571} INFO - 24/01/28 12:41:54 INFO RetryInvocationHandler: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking ApplicationClientProtocolPBClientImpl.getNewApplication over null after 29 failover attempts. Trying to failover after sleeping for 28139ms.
[2024-01-28T12:42:24.360+0100] {spark_submit.py:571} INFO - 24/01/28 12:42:24 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-28T12:42:25.362+0100] {spark_submit.py:571} INFO - 24/01/28 12:42:25 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-28T12:42:26.375+0100] {spark_submit.py:571} INFO - 24/01/28 12:42:26 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-28T12:42:27.385+0100] {spark_submit.py:571} INFO - 24/01/28 12:42:27 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-28T12:42:28.393+0100] {spark_submit.py:571} INFO - 24/01/28 12:42:28 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-28T12:42:29.465+0100] {spark_submit.py:571} INFO - 24/01/28 12:42:29 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-28T12:42:30.468+0100] {spark_submit.py:571} INFO - 24/01/28 12:42:30 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-28T12:42:31.485+0100] {spark_submit.py:571} INFO - 24/01/28 12:42:31 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-28T12:42:32.487+0100] {spark_submit.py:571} INFO - 24/01/28 12:42:32 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-28T12:42:33.548+0100] {spark_submit.py:571} INFO - 24/01/28 12:42:33 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-28T12:42:34.611+0100] {spark_submit.py:571} INFO - 24/01/28 12:42:34 ERROR SparkContext: Error initializing SparkContext.
[2024-01-28T12:42:34.627+0100] {spark_submit.py:571} INFO - java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort
[2024-01-28T12:42:34.641+0100] {spark_submit.py:571} INFO - at java.base/jdk.internal.reflect.GeneratedConstructorAccessor28.newInstance(Unknown Source)
[2024-01-28T12:42:34.642+0100] {spark_submit.py:571} INFO - at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
[2024-01-28T12:42:34.643+0100] {spark_submit.py:571} INFO - at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)
[2024-01-28T12:42:34.644+0100] {spark_submit.py:571} INFO - at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:913)
[2024-01-28T12:42:34.645+0100] {spark_submit.py:571} INFO - at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:824)
[2024-01-28T12:42:34.645+0100] {spark_submit.py:571} INFO - at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1616)
[2024-01-28T12:42:34.645+0100] {spark_submit.py:571} INFO - at org.apache.hadoop.ipc.Client.call(Client.java:1558)
[2024-01-28T12:42:34.645+0100] {spark_submit.py:571} INFO - at org.apache.hadoop.ipc.Client.call(Client.java:1455)
[2024-01-28T12:42:34.646+0100] {spark_submit.py:571} INFO - at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:242)
[2024-01-28T12:42:34.646+0100] {spark_submit.py:571} INFO - at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:129)
[2024-01-28T12:42:34.646+0100] {spark_submit.py:571} INFO - at com.sun.proxy.$Proxy34.getNewApplication(Unknown Source)
[2024-01-28T12:42:34.646+0100] {spark_submit.py:571} INFO - at org.apache.hadoop.yarn.api.impl.pb.client.ApplicationClientProtocolPBClientImpl.getNewApplication(ApplicationClientProtocolPBClientImpl.java:286)
[2024-01-28T12:42:34.646+0100] {spark_submit.py:571} INFO - at jdk.internal.reflect.GeneratedMethodAccessor4.invoke(Unknown Source)
[2024-01-28T12:42:34.647+0100] {spark_submit.py:571} INFO - at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
[2024-01-28T12:42:34.647+0100] {spark_submit.py:571} INFO - at java.base/java.lang.reflect.Method.invoke(Method.java:566)
[2024-01-28T12:42:34.647+0100] {spark_submit.py:571} INFO - at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
[2024-01-28T12:42:34.647+0100] {spark_submit.py:571} INFO - at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
[2024-01-28T12:42:34.649+0100] {spark_submit.py:571} INFO - at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
[2024-01-28T12:42:34.650+0100] {spark_submit.py:571} INFO - at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
[2024-01-28T12:42:34.651+0100] {spark_submit.py:571} INFO - at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
[2024-01-28T12:42:34.651+0100] {spark_submit.py:571} INFO - at com.sun.proxy.$Proxy35.getNewApplication(Unknown Source)
[2024-01-28T12:42:34.651+0100] {spark_submit.py:571} INFO - at org.apache.hadoop.yarn.client.api.impl.YarnClientImpl.getNewApplication(YarnClientImpl.java:284)
[2024-01-28T12:42:34.651+0100] {spark_submit.py:571} INFO - at org.apache.hadoop.yarn.client.api.impl.YarnClientImpl.createApplication(YarnClientImpl.java:292)
[2024-01-28T12:42:34.651+0100] {spark_submit.py:571} INFO - at org.apache.spark.deploy.yarn.Client.submitApplication(Client.scala:200)
[2024-01-28T12:42:34.652+0100] {spark_submit.py:571} INFO - at org.apache.spark.scheduler.cluster.YarnClientSchedulerBackend.start(YarnClientSchedulerBackend.scala:62)
[2024-01-28T12:42:34.652+0100] {spark_submit.py:571} INFO - at org.apache.spark.scheduler.TaskSchedulerImpl.start(TaskSchedulerImpl.scala:222)
[2024-01-28T12:42:34.657+0100] {spark_submit.py:571} INFO - at org.apache.spark.SparkContext.<init>(SparkContext.scala:595)
[2024-01-28T12:42:34.660+0100] {spark_submit.py:571} INFO - at org.apache.spark.SparkContext$.getOrCreate(SparkContext.scala:2714)
[2024-01-28T12:42:34.661+0100] {spark_submit.py:571} INFO - at org.apache.spark.sql.SparkSession$Builder.$anonfun$getOrCreate$2(SparkSession.scala:953)
[2024-01-28T12:42:34.662+0100] {spark_submit.py:571} INFO - at scala.Option.getOrElse(Option.scala:189)
[2024-01-28T12:42:34.662+0100] {spark_submit.py:571} INFO - at org.apache.spark.sql.SparkSession$Builder.getOrCreate(SparkSession.scala:947)
[2024-01-28T12:42:34.664+0100] {spark_submit.py:571} INFO - at main.scala.mnm.MnMcount$.main(MnMcount.scala:17)
[2024-01-28T12:42:34.664+0100] {spark_submit.py:571} INFO - at main.scala.mnm.MnMcount.main(MnMcount.scala)
[2024-01-28T12:42:34.665+0100] {spark_submit.py:571} INFO - at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
[2024-01-28T12:42:34.665+0100] {spark_submit.py:571} INFO - at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
[2024-01-28T12:42:34.665+0100] {spark_submit.py:571} INFO - at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
[2024-01-28T12:42:34.665+0100] {spark_submit.py:571} INFO - at java.base/java.lang.reflect.Method.invoke(Method.java:566)
[2024-01-28T12:42:34.666+0100] {spark_submit.py:571} INFO - at org.apache.spark.deploy.JavaMainApplication.start(SparkApplication.scala:52)
[2024-01-28T12:42:34.666+0100] {spark_submit.py:571} INFO - at org.apache.spark.deploy.SparkSubmit.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:984)
[2024-01-28T12:42:34.673+0100] {spark_submit.py:571} INFO - at org.apache.spark.deploy.SparkSubmit.doRunMain$1(SparkSubmit.scala:191)
[2024-01-28T12:42:34.673+0100] {spark_submit.py:571} INFO - at org.apache.spark.deploy.SparkSubmit.submit(SparkSubmit.scala:214)
[2024-01-28T12:42:34.673+0100] {spark_submit.py:571} INFO - at org.apache.spark.deploy.SparkSubmit.doSubmit(SparkSubmit.scala:90)
[2024-01-28T12:42:34.673+0100] {spark_submit.py:571} INFO - at org.apache.spark.deploy.SparkSubmit$$anon$2.doSubmit(SparkSubmit.scala:1072)
[2024-01-28T12:42:34.673+0100] {spark_submit.py:571} INFO - at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:1081)
[2024-01-28T12:42:34.674+0100] {spark_submit.py:571} INFO - at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)
[2024-01-28T12:42:34.674+0100] {spark_submit.py:571} INFO - Caused by: java.net.ConnectException: Connection refused
[2024-01-28T12:42:34.674+0100] {spark_submit.py:571} INFO - at java.base/sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
[2024-01-28T12:42:34.674+0100] {spark_submit.py:571} INFO - at java.base/sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:777)
[2024-01-28T12:42:34.676+0100] {spark_submit.py:571} INFO - at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:205)
[2024-01-28T12:42:34.677+0100] {spark_submit.py:571} INFO - at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:586)
[2024-01-28T12:42:34.678+0100] {spark_submit.py:571} INFO - at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:711)
[2024-01-28T12:42:34.678+0100] {spark_submit.py:571} INFO - at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:833)
[2024-01-28T12:42:34.679+0100] {spark_submit.py:571} INFO - at org.apache.hadoop.ipc.Client$Connection.access$3800(Client.java:414)
[2024-01-28T12:42:34.679+0100] {spark_submit.py:571} INFO - at org.apache.hadoop.ipc.Client.getConnection(Client.java:1677)
[2024-01-28T12:42:34.680+0100] {spark_submit.py:571} INFO - at org.apache.hadoop.ipc.Client.call(Client.java:1502)
[2024-01-28T12:42:34.680+0100] {spark_submit.py:571} INFO - ... 38 more
[2024-01-28T12:42:35.084+0100] {spark_submit.py:571} INFO - 24/01/28 12:42:35 INFO SparkUI: Stopped Spark web UI at http://10.0.2.15:4040
[2024-01-28T12:42:35.150+0100] {spark_submit.py:571} INFO - 24/01/28 12:42:35 WARN YarnSchedulerBackend$YarnSchedulerEndpoint: Attempted to send shutdown message before the AM has registered!
[2024-01-28T12:42:35.346+0100] {spark_submit.py:571} INFO - 24/01/28 12:42:35 WARN YarnSchedulerBackend$YarnSchedulerEndpoint: Attempted to request executors before the AM has registered!
[2024-01-28T12:42:35.545+0100] {spark_submit.py:571} INFO - 24/01/28 12:42:35 INFO YarnClientSchedulerBackend: Shutting down all executors
[2024-01-28T12:42:35.644+0100] {spark_submit.py:571} INFO - 24/01/28 12:42:35 INFO YarnSchedulerBackend$YarnDriverEndpoint: Asking each executor to shut down
[2024-01-28T12:42:35.749+0100] {spark_submit.py:571} INFO - 24/01/28 12:42:35 INFO YarnClientSchedulerBackend: YARN client scheduler backend Stopped
[2024-01-28T12:42:36.793+0100] {spark_submit.py:571} INFO - 24/01/28 12:42:36 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
[2024-01-28T12:42:37.001+0100] {spark_submit.py:571} INFO - 24/01/28 12:42:37 INFO MemoryStore: MemoryStore cleared
[2024-01-28T12:42:37.020+0100] {spark_submit.py:571} INFO - 24/01/28 12:42:37 INFO BlockManager: BlockManager stopped
[2024-01-28T12:42:37.240+0100] {spark_submit.py:571} INFO - 24/01/28 12:42:37 INFO BlockManagerMaster: BlockManagerMaster stopped
[2024-01-28T12:42:37.242+0100] {spark_submit.py:571} INFO - 24/01/28 12:42:37 WARN MetricsSystem: Stopping a MetricsSystem that is not running
[2024-01-28T12:42:37.324+0100] {spark_submit.py:571} INFO - 24/01/28 12:42:37 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
[2024-01-28T12:42:37.870+0100] {spark_submit.py:571} INFO - 24/01/28 12:42:37 INFO SparkContext: Successfully stopped SparkContext
[2024-01-28T12:42:37.892+0100] {spark_submit.py:571} INFO - Exception in thread "main" java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort
[2024-01-28T12:42:37.902+0100] {spark_submit.py:571} INFO - at java.base/jdk.internal.reflect.GeneratedConstructorAccessor28.newInstance(Unknown Source)
[2024-01-28T12:42:37.908+0100] {spark_submit.py:571} INFO - at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
[2024-01-28T12:42:37.922+0100] {spark_submit.py:571} INFO - at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)
[2024-01-28T12:42:37.925+0100] {spark_submit.py:571} INFO - at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:913)
[2024-01-28T12:42:37.926+0100] {spark_submit.py:571} INFO - at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:824)
[2024-01-28T12:42:37.932+0100] {spark_submit.py:571} INFO - at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1616)
[2024-01-28T12:42:37.932+0100] {spark_submit.py:571} INFO - at org.apache.hadoop.ipc.Client.call(Client.java:1558)
[2024-01-28T12:42:37.933+0100] {spark_submit.py:571} INFO - at org.apache.hadoop.ipc.Client.call(Client.java:1455)
[2024-01-28T12:42:37.933+0100] {spark_submit.py:571} INFO - at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:242)
[2024-01-28T12:42:37.933+0100] {spark_submit.py:571} INFO - at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:129)
[2024-01-28T12:42:37.935+0100] {spark_submit.py:571} INFO - at com.sun.proxy.$Proxy34.getNewApplication(Unknown Source)
[2024-01-28T12:42:37.936+0100] {spark_submit.py:571} INFO - at org.apache.hadoop.yarn.api.impl.pb.client.ApplicationClientProtocolPBClientImpl.getNewApplication(ApplicationClientProtocolPBClientImpl.java:286)
[2024-01-28T12:42:37.936+0100] {spark_submit.py:571} INFO - at jdk.internal.reflect.GeneratedMethodAccessor4.invoke(Unknown Source)
[2024-01-28T12:42:37.937+0100] {spark_submit.py:571} INFO - at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
[2024-01-28T12:42:37.937+0100] {spark_submit.py:571} INFO - at java.base/java.lang.reflect.Method.invoke(Method.java:566)
[2024-01-28T12:42:37.937+0100] {spark_submit.py:571} INFO - at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
[2024-01-28T12:42:37.938+0100] {spark_submit.py:571} INFO - at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
[2024-01-28T12:42:37.938+0100] {spark_submit.py:571} INFO - at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
[2024-01-28T12:42:37.939+0100] {spark_submit.py:571} INFO - at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
[2024-01-28T12:42:37.939+0100] {spark_submit.py:571} INFO - at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
[2024-01-28T12:42:37.940+0100] {spark_submit.py:571} INFO - at com.sun.proxy.$Proxy35.getNewApplication(Unknown Source)
[2024-01-28T12:42:37.940+0100] {spark_submit.py:571} INFO - at org.apache.hadoop.yarn.client.api.impl.YarnClientImpl.getNewApplication(YarnClientImpl.java:284)
[2024-01-28T12:42:37.940+0100] {spark_submit.py:571} INFO - at org.apache.hadoop.yarn.client.api.impl.YarnClientImpl.createApplication(YarnClientImpl.java:292)
[2024-01-28T12:42:37.940+0100] {spark_submit.py:571} INFO - at org.apache.spark.deploy.yarn.Client.submitApplication(Client.scala:200)
[2024-01-28T12:42:37.940+0100] {spark_submit.py:571} INFO - at org.apache.spark.scheduler.cluster.YarnClientSchedulerBackend.start(YarnClientSchedulerBackend.scala:62)
[2024-01-28T12:42:37.940+0100] {spark_submit.py:571} INFO - at org.apache.spark.scheduler.TaskSchedulerImpl.start(TaskSchedulerImpl.scala:222)
[2024-01-28T12:42:37.940+0100] {spark_submit.py:571} INFO - at org.apache.spark.SparkContext.<init>(SparkContext.scala:595)
[2024-01-28T12:42:37.940+0100] {spark_submit.py:571} INFO - at org.apache.spark.SparkContext$.getOrCreate(SparkContext.scala:2714)
[2024-01-28T12:42:37.941+0100] {spark_submit.py:571} INFO - at org.apache.spark.sql.SparkSession$Builder.$anonfun$getOrCreate$2(SparkSession.scala:953)
[2024-01-28T12:42:37.942+0100] {spark_submit.py:571} INFO - at scala.Option.getOrElse(Option.scala:189)
[2024-01-28T12:42:37.942+0100] {spark_submit.py:571} INFO - at org.apache.spark.sql.SparkSession$Builder.getOrCreate(SparkSession.scala:947)
[2024-01-28T12:42:37.942+0100] {spark_submit.py:571} INFO - at main.scala.mnm.MnMcount$.main(MnMcount.scala:17)
[2024-01-28T12:42:37.942+0100] {spark_submit.py:571} INFO - at main.scala.mnm.MnMcount.main(MnMcount.scala)
[2024-01-28T12:42:37.942+0100] {spark_submit.py:571} INFO - at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
[2024-01-28T12:42:37.943+0100] {spark_submit.py:571} INFO - at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
[2024-01-28T12:42:37.943+0100] {spark_submit.py:571} INFO - at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
[2024-01-28T12:42:37.943+0100] {spark_submit.py:571} INFO - at java.base/java.lang.reflect.Method.invoke(Method.java:566)
[2024-01-28T12:42:37.943+0100] {spark_submit.py:571} INFO - at org.apache.spark.deploy.JavaMainApplication.start(SparkApplication.scala:52)
[2024-01-28T12:42:37.943+0100] {spark_submit.py:571} INFO - at org.apache.spark.deploy.SparkSubmit.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:984)
[2024-01-28T12:42:37.944+0100] {spark_submit.py:571} INFO - at org.apache.spark.deploy.SparkSubmit.doRunMain$1(SparkSubmit.scala:191)
[2024-01-28T12:42:37.948+0100] {spark_submit.py:571} INFO - at org.apache.spark.deploy.SparkSubmit.submit(SparkSubmit.scala:214)
[2024-01-28T12:42:37.949+0100] {spark_submit.py:571} INFO - at org.apache.spark.deploy.SparkSubmit.doSubmit(SparkSubmit.scala:90)
[2024-01-28T12:42:37.949+0100] {spark_submit.py:571} INFO - at org.apache.spark.deploy.SparkSubmit$$anon$2.doSubmit(SparkSubmit.scala:1072)
[2024-01-28T12:42:37.949+0100] {spark_submit.py:571} INFO - at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:1081)
[2024-01-28T12:42:37.949+0100] {spark_submit.py:571} INFO - at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)
[2024-01-28T12:42:37.951+0100] {spark_submit.py:571} INFO - Caused by: java.net.ConnectException: Connection refused
[2024-01-28T12:42:37.952+0100] {spark_submit.py:571} INFO - at java.base/sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
[2024-01-28T12:42:37.954+0100] {spark_submit.py:571} INFO - at java.base/sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:777)
[2024-01-28T12:42:37.954+0100] {spark_submit.py:571} INFO - at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:205)
[2024-01-28T12:42:37.955+0100] {spark_submit.py:571} INFO - at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:586)
[2024-01-28T12:42:37.955+0100] {spark_submit.py:571} INFO - at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:711)
[2024-01-28T12:42:37.956+0100] {spark_submit.py:571} INFO - at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:833)
[2024-01-28T12:42:37.956+0100] {spark_submit.py:571} INFO - at org.apache.hadoop.ipc.Client$Connection.access$3800(Client.java:414)
[2024-01-28T12:42:37.956+0100] {spark_submit.py:571} INFO - at org.apache.hadoop.ipc.Client.getConnection(Client.java:1677)
[2024-01-28T12:42:37.956+0100] {spark_submit.py:571} INFO - at org.apache.hadoop.ipc.Client.call(Client.java:1502)
[2024-01-28T12:42:37.956+0100] {spark_submit.py:571} INFO - ... 38 more
[2024-01-28T12:42:38.185+0100] {spark_submit.py:571} INFO - 24/01/28 12:42:38 INFO ShutdownHookManager: Shutdown hook called
[2024-01-28T12:42:38.192+0100] {spark_submit.py:571} INFO - 24/01/28 12:42:38 INFO ShutdownHookManager: Deleting directory /tmp/spark-b3a1face-1e8a-4b26-a157-2dcf9bba5a34
[2024-01-28T12:42:38.459+0100] {spark_submit.py:571} INFO - 24/01/28 12:42:38 INFO ShutdownHookManager: Deleting directory /tmp/spark-7a9a7cf5-533e-43c5-8f48-e4d029d72aa3
[2024-01-28T12:42:39.664+0100] {taskinstance.py:2699} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/ubuntu/.local/lib/python3.10/site-packages/airflow/models/taskinstance.py", line 433, in _execute_task
    result = execute_callable(context=context, **execute_callable_kwargs)
  File "/home/ubuntu/.local/lib/python3.10/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 174, in execute
    self._hook.submit(self._application)
  File "/home/ubuntu/.local/lib/python3.10/site-packages/airflow/providers/apache/spark/hooks/spark_submit.py", line 502, in submit
    raise AirflowException(
airflow.exceptions.AirflowException: Cannot execute: spark-submit --master yarn --conf spark.master=local[*] --conf spark.yarn.conf.dir=/usr/local/hadoop/etc/hadoop --name your_spark_job --class main.scala.mnm.MnMcount --queue root.default hdfs://localhost:9000/user/project/datalake/main-scala-mnm_2.12-1.0.jar. Error code is: 1.
[2024-01-28T12:42:39.761+0100] {taskinstance.py:1138} INFO - Marking task as UP_FOR_RETRY. dag_id=jeniferhdfs, task_id=submit_spark_job, execution_date=20240128T112157, start_date=20240128T112310, end_date=20240128T114239
[2024-01-28T12:42:40.201+0100] {standard_task_runner.py:107} ERROR - Failed to execute job 72 for task submit_spark_job (Cannot execute: spark-submit --master yarn --conf spark.master=local[*] --conf spark.yarn.conf.dir=/usr/local/hadoop/etc/hadoop --name your_spark_job --class main.scala.mnm.MnMcount --queue root.default hdfs://localhost:9000/user/project/datalake/main-scala-mnm_2.12-1.0.jar. Error code is: 1.; 24094)
[2024-01-28T12:42:40.299+0100] {local_task_job_runner.py:234} INFO - Task exited with return code 1
[2024-01-28T12:42:40.585+0100] {taskinstance.py:3281} INFO - 0 downstream tasks scheduled from follow-on schedule check
