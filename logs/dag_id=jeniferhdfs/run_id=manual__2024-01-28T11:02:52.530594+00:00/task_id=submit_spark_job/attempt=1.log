[2024-01-28T12:04:31.629+0100] {taskinstance.py:1957} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: jeniferhdfs.submit_spark_job manual__2024-01-28T11:02:52.530594+00:00 [queued]>
[2024-01-28T12:04:31.665+0100] {taskinstance.py:1957} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: jeniferhdfs.submit_spark_job manual__2024-01-28T11:02:52.530594+00:00 [queued]>
[2024-01-28T12:04:31.676+0100] {taskinstance.py:2171} INFO - Starting attempt 1 of 2
[2024-01-28T12:04:31.796+0100] {taskinstance.py:2192} INFO - Executing <Task(SparkSubmitOperator): submit_spark_job> on 2024-01-28 11:02:52.530594+00:00
[2024-01-28T12:04:31.827+0100] {standard_task_runner.py:60} INFO - Started process 22894 to run task
[2024-01-28T12:04:31.865+0100] {standard_task_runner.py:87} INFO - Running: ['airflow', 'tasks', 'run', 'jeniferhdfs', 'submit_spark_job', 'manual__2024-01-28T11:02:52.530594+00:00', '--job-id', '70', '--raw', '--subdir', 'DAGS_FOLDER/hdfsDag.py', '--cfg-path', '/tmp/tmpppfpoe3l']
[2024-01-28T12:04:31.873+0100] {standard_task_runner.py:88} INFO - Job 70: Subtask submit_spark_job
[2024-01-28T12:04:32.349+0100] {task_command.py:423} INFO - Running <TaskInstance: jeniferhdfs.submit_spark_job manual__2024-01-28T11:02:52.530594+00:00 [running]> on host ubuntu.ubuntu.virtualbox.org
[2024-01-28T12:04:32.871+0100] {taskinstance.py:2481} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='jenifer' AIRFLOW_CTX_DAG_ID='jeniferhdfs' AIRFLOW_CTX_TASK_ID='submit_spark_job' AIRFLOW_CTX_EXECUTION_DATE='2024-01-28T11:02:52.530594+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2024-01-28T11:02:52.530594+00:00'
[2024-01-28T12:04:32.897+0100] {base.py:83} INFO - Using connection ID 'spark_default' for task execution.
[2024-01-28T12:04:32.901+0100] {spark_submit.py:401} INFO - Spark-Submit cmd: spark-submit --master yarn --conf spark.master=local[*] --conf spark.yarn.conf.dir=/usr/local/hadoop/etc/hadoop --name your_spark_job --class main.scala.mnm.MnMcount --queue root.default hdfs://localhost:9000/user/project/datalake/main-scala-mnm_2.12-1.0.jar
[2024-01-28T12:05:24.310+0100] {spark_submit.py:571} INFO - 24/01/28 12:05:24 WARN Utils: Your hostname, ubuntu resolves to a loopback address: 127.0.1.1; using 10.0.2.15 instead (on interface enp0s3)
[2024-01-28T12:05:24.610+0100] {spark_submit.py:571} INFO - 24/01/28 12:05:24 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address
[2024-01-28T12:06:18.128+0100] {spark_submit.py:571} INFO - 24/01/28 12:06:17 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[2024-01-28T12:14:25.044+0100] {spark_submit.py:571} INFO - 24/01/28 12:14:24 INFO SparkContext: Running Spark version 3.3.4
[2024-01-28T12:14:30.112+0100] {spark_submit.py:571} INFO - 24/01/28 12:14:30 INFO ResourceUtils: ==============================================================
[2024-01-28T12:14:30.208+0100] {spark_submit.py:571} INFO - 24/01/28 12:14:30 INFO ResourceUtils: No custom resources configured for spark.driver.
[2024-01-28T12:14:30.210+0100] {spark_submit.py:571} INFO - 24/01/28 12:14:30 INFO ResourceUtils: ==============================================================
[2024-01-28T12:14:30.217+0100] {spark_submit.py:571} INFO - 24/01/28 12:14:30 INFO SparkContext: Submitted application: MnMCount
[2024-01-28T12:14:30.776+0100] {spark_submit.py:571} INFO - 24/01/28 12:14:30 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
[2024-01-28T12:14:31.253+0100] {spark_submit.py:571} INFO - 24/01/28 12:14:31 INFO ResourceProfile: Limiting resource is cpus at 1 tasks per executor
[2024-01-28T12:14:31.262+0100] {spark_submit.py:571} INFO - 24/01/28 12:14:31 INFO ResourceProfileManager: Added ResourceProfile id: 0
[2024-01-28T12:14:33.914+0100] {spark_submit.py:571} INFO - 24/01/28 12:14:33 INFO SecurityManager: Changing view acls to: ubuntu
[2024-01-28T12:14:33.996+0100] {spark_submit.py:571} INFO - 24/01/28 12:14:33 INFO SecurityManager: Changing modify acls to: ubuntu
[2024-01-28T12:14:34.016+0100] {spark_submit.py:571} INFO - 24/01/28 12:14:34 INFO SecurityManager: Changing view acls groups to:
[2024-01-28T12:14:34.022+0100] {spark_submit.py:571} INFO - 24/01/28 12:14:34 INFO SecurityManager: Changing modify acls groups to:
[2024-01-28T12:14:34.036+0100] {spark_submit.py:571} INFO - 24/01/28 12:14:34 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(ubuntu); groups with view permissions: Set(); users  with modify permissions: Set(ubuntu); groups with modify permissions: Set()
[2024-01-28T12:15:07.274+0100] {spark_submit.py:571} INFO - 24/01/28 12:15:07 INFO Utils: Successfully started service 'sparkDriver' on port 34879.
[2024-01-28T12:15:10.244+0100] {spark_submit.py:571} INFO - 24/01/28 12:15:10 INFO SparkEnv: Registering MapOutputTracker
[2024-01-28T12:15:16.078+0100] {spark_submit.py:571} INFO - 24/01/28 12:15:15 INFO SparkEnv: Registering BlockManagerMaster
[2024-01-28T12:15:19.307+0100] {spark_submit.py:571} INFO - 24/01/28 12:15:19 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
[2024-01-28T12:15:19.321+0100] {spark_submit.py:571} INFO - 24/01/28 12:15:19 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
[2024-01-28T12:15:19.945+0100] {spark_submit.py:571} INFO - 24/01/28 12:15:19 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
[2024-01-28T12:15:20.874+0100] {spark_submit.py:571} INFO - 24/01/28 12:15:20 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-abbe6cc0-4f7f-42a7-9507-ef169e3af9ad
[2024-01-28T12:15:21.098+0100] {spark_submit.py:571} INFO - 24/01/28 12:15:21 INFO MemoryStore: MemoryStore started with capacity 434.4 MiB
[2024-01-28T12:15:21.793+0100] {spark_submit.py:571} INFO - 24/01/28 12:15:21 INFO SparkEnv: Registering OutputCommitCoordinator
[2024-01-28T12:15:27.489+0100] {spark_submit.py:571} INFO - 24/01/28 12:15:27 INFO Utils: Successfully started service 'SparkUI' on port 4040.
[2024-01-28T12:15:29.157+0100] {spark_submit.py:571} INFO - 24/01/28 12:15:29 INFO SparkContext: Added JAR hdfs://localhost:9000/user/project/datalake/main-scala-mnm_2.12-1.0.jar at hdfs://localhost:9000/user/project/datalake/main-scala-mnm_2.12-1.0.jar with timestamp 1706440464382
[2024-01-28T12:15:31.128+0100] {spark_submit.py:571} INFO - 24/01/28 12:15:31 INFO DefaultNoHARMFailoverProxyProvider: Connecting to ResourceManager at /0.0.0.0:8032
[2024-01-28T12:15:33.000+0100] {spark_submit.py:571} INFO - 24/01/28 12:15:32 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-28T12:15:34.002+0100] {spark_submit.py:571} INFO - 24/01/28 12:15:34 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-28T12:15:35.007+0100] {spark_submit.py:571} INFO - 24/01/28 12:15:35 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-28T12:15:36.009+0100] {spark_submit.py:571} INFO - 24/01/28 12:15:36 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-28T12:15:37.015+0100] {spark_submit.py:571} INFO - 24/01/28 12:15:37 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-28T12:15:38.017+0100] {spark_submit.py:571} INFO - 24/01/28 12:15:38 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-28T12:15:39.023+0100] {spark_submit.py:571} INFO - 24/01/28 12:15:39 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-28T12:15:40.025+0100] {spark_submit.py:571} INFO - 24/01/28 12:15:40 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-28T12:15:41.028+0100] {spark_submit.py:571} INFO - 24/01/28 12:15:41 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-28T12:15:42.040+0100] {spark_submit.py:571} INFO - 24/01/28 12:15:42 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-28T12:15:43.076+0100] {spark_submit.py:571} INFO - 24/01/28 12:15:43 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-28T12:15:44.098+0100] {spark_submit.py:571} INFO - 24/01/28 12:15:44 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-28T12:15:45.121+0100] {spark_submit.py:571} INFO - 24/01/28 12:15:45 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-28T12:15:46.145+0100] {spark_submit.py:571} INFO - 24/01/28 12:15:46 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-28T12:15:47.160+0100] {spark_submit.py:571} INFO - 24/01/28 12:15:47 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-28T12:15:48.164+0100] {spark_submit.py:571} INFO - 24/01/28 12:15:48 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-28T12:15:49.171+0100] {spark_submit.py:571} INFO - 24/01/28 12:15:49 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-28T12:15:50.173+0100] {spark_submit.py:571} INFO - 24/01/28 12:15:50 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-28T12:15:51.175+0100] {spark_submit.py:571} INFO - 24/01/28 12:15:51 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-28T12:15:52.186+0100] {spark_submit.py:571} INFO - 24/01/28 12:15:52 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-28T12:15:52.197+0100] {spark_submit.py:571} INFO - 24/01/28 12:15:52 INFO RetryInvocationHandler: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking ApplicationClientProtocolPBClientImpl.getNewApplication over null after 1 failover attempts. Trying to failover after sleeping for 34877ms.
[2024-01-28T12:16:28.169+0100] {spark_submit.py:571} INFO - 24/01/28 12:16:28 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-28T12:16:29.182+0100] {spark_submit.py:571} INFO - 24/01/28 12:16:29 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-28T12:16:30.184+0100] {spark_submit.py:571} INFO - 24/01/28 12:16:30 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-28T12:16:31.189+0100] {spark_submit.py:571} INFO - 24/01/28 12:16:31 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-28T12:16:32.192+0100] {spark_submit.py:571} INFO - 24/01/28 12:16:32 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-28T12:16:33.208+0100] {spark_submit.py:571} INFO - 24/01/28 12:16:33 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-28T12:16:34.219+0100] {spark_submit.py:571} INFO - 24/01/28 12:16:34 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-28T12:16:35.227+0100] {spark_submit.py:571} INFO - 24/01/28 12:16:35 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-28T12:16:36.233+0100] {spark_submit.py:571} INFO - 24/01/28 12:16:36 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-28T12:16:37.232+0100] {spark_submit.py:571} INFO - 24/01/28 12:16:37 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-28T12:16:37.255+0100] {spark_submit.py:571} INFO - 24/01/28 12:16:37 INFO RetryInvocationHandler: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking ApplicationClientProtocolPBClientImpl.getNewApplication over null after 2 failover attempts. Trying to failover after sleeping for 23438ms.
[2024-01-28T12:17:02.863+0100] {spark_submit.py:571} INFO - 24/01/28 12:17:02 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-28T12:17:03.858+0100] {spark_submit.py:571} INFO - 24/01/28 12:17:03 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-28T12:17:04.864+0100] {spark_submit.py:571} INFO - 24/01/28 12:17:04 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-28T12:17:05.868+0100] {spark_submit.py:571} INFO - 24/01/28 12:17:05 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-28T12:17:06.873+0100] {spark_submit.py:571} INFO - 24/01/28 12:17:06 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-28T12:17:07.881+0100] {spark_submit.py:571} INFO - 24/01/28 12:17:07 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-28T12:17:08.891+0100] {spark_submit.py:571} INFO - 24/01/28 12:17:08 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-28T12:17:09.900+0100] {spark_submit.py:571} INFO - 24/01/28 12:17:09 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-28T12:17:10.905+0100] {spark_submit.py:571} INFO - 24/01/28 12:17:10 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-28T12:17:11.910+0100] {spark_submit.py:571} INFO - 24/01/28 12:17:11 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-28T12:17:11.955+0100] {spark_submit.py:571} INFO - 24/01/28 12:17:11 INFO RetryInvocationHandler: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking ApplicationClientProtocolPBClientImpl.getNewApplication over null after 3 failover attempts. Trying to failover after sleeping for 37617ms.
[2024-01-28T12:17:50.823+0100] {spark_submit.py:571} INFO - 24/01/28 12:17:50 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-28T12:17:51.828+0100] {spark_submit.py:571} INFO - 24/01/28 12:17:51 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-28T12:17:52.855+0100] {spark_submit.py:571} INFO - 24/01/28 12:17:52 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-28T12:17:53.916+0100] {spark_submit.py:571} INFO - 24/01/28 12:17:53 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-28T12:17:54.934+0100] {spark_submit.py:571} INFO - 24/01/28 12:17:54 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-28T12:17:55.962+0100] {spark_submit.py:571} INFO - 24/01/28 12:17:55 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-28T12:17:56.975+0100] {spark_submit.py:571} INFO - 24/01/28 12:17:56 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-28T12:17:57.989+0100] {spark_submit.py:571} INFO - 24/01/28 12:17:57 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-28T12:17:58.993+0100] {spark_submit.py:571} INFO - 24/01/28 12:17:58 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-28T12:17:59.999+0100] {spark_submit.py:571} INFO - 24/01/28 12:17:59 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-28T12:18:00.032+0100] {spark_submit.py:571} INFO - 24/01/28 12:18:00 INFO RetryInvocationHandler: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking ApplicationClientProtocolPBClientImpl.getNewApplication over null after 4 failover attempts. Trying to failover after sleeping for 36952ms.
[2024-01-28T12:18:38.033+0100] {spark_submit.py:571} INFO - 24/01/28 12:18:38 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-28T12:18:39.043+0100] {spark_submit.py:571} INFO - 24/01/28 12:18:39 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-28T12:18:40.046+0100] {spark_submit.py:571} INFO - 24/01/28 12:18:40 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-28T12:18:41.063+0100] {spark_submit.py:571} INFO - 24/01/28 12:18:41 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-28T12:18:42.066+0100] {spark_submit.py:571} INFO - 24/01/28 12:18:42 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-28T12:18:43.073+0100] {spark_submit.py:571} INFO - 24/01/28 12:18:43 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-28T12:18:44.105+0100] {spark_submit.py:571} INFO - 24/01/28 12:18:44 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-28T12:18:45.166+0100] {spark_submit.py:571} INFO - 24/01/28 12:18:45 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-28T12:18:46.180+0100] {spark_submit.py:571} INFO - 24/01/28 12:18:46 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-28T12:18:47.188+0100] {spark_submit.py:571} INFO - 24/01/28 12:18:47 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-28T12:18:47.196+0100] {spark_submit.py:571} INFO - 24/01/28 12:18:47 INFO RetryInvocationHandler: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking ApplicationClientProtocolPBClientImpl.getNewApplication over null after 5 failover attempts. Trying to failover after sleeping for 33226ms.
[2024-01-28T12:19:21.439+0100] {spark_submit.py:571} INFO - 24/01/28 12:19:21 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-28T12:19:22.443+0100] {spark_submit.py:571} INFO - 24/01/28 12:19:22 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-28T12:19:23.459+0100] {spark_submit.py:571} INFO - 24/01/28 12:19:23 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-28T12:19:24.464+0100] {spark_submit.py:571} INFO - 24/01/28 12:19:24 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-28T12:19:25.470+0100] {spark_submit.py:571} INFO - 24/01/28 12:19:25 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-28T12:19:26.469+0100] {spark_submit.py:571} INFO - 24/01/28 12:19:26 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-28T12:19:27.485+0100] {spark_submit.py:571} INFO - 24/01/28 12:19:27 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-28T12:19:28.484+0100] {spark_submit.py:571} INFO - 24/01/28 12:19:28 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-28T12:19:29.491+0100] {spark_submit.py:571} INFO - 24/01/28 12:19:29 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-28T12:19:30.495+0100] {spark_submit.py:571} INFO - 24/01/28 12:19:30 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-28T12:19:30.501+0100] {spark_submit.py:571} INFO - 24/01/28 12:19:30 INFO RetryInvocationHandler: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking ApplicationClientProtocolPBClientImpl.getNewApplication over null after 6 failover attempts. Trying to failover after sleeping for 42443ms.
[2024-01-28T12:20:13.957+0100] {spark_submit.py:571} INFO - 24/01/28 12:20:13 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-28T12:20:14.982+0100] {spark_submit.py:571} INFO - 24/01/28 12:20:14 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-28T12:20:15.986+0100] {spark_submit.py:571} INFO - 24/01/28 12:20:15 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-28T12:20:16.992+0100] {spark_submit.py:571} INFO - 24/01/28 12:20:16 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-28T12:20:18.007+0100] {spark_submit.py:571} INFO - 24/01/28 12:20:18 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-28T12:20:19.020+0100] {spark_submit.py:571} INFO - 24/01/28 12:20:19 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-28T12:20:20.030+0100] {spark_submit.py:571} INFO - 24/01/28 12:20:20 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-28T12:20:21.056+0100] {spark_submit.py:571} INFO - 24/01/28 12:20:21 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-28T12:20:22.060+0100] {spark_submit.py:571} INFO - 24/01/28 12:20:22 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-28T12:20:23.061+0100] {spark_submit.py:571} INFO - 24/01/28 12:20:23 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-28T12:20:23.136+0100] {spark_submit.py:571} INFO - 24/01/28 12:20:23 INFO RetryInvocationHandler: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking ApplicationClientProtocolPBClientImpl.getNewApplication over null after 7 failover attempts. Trying to failover after sleeping for 22850ms.
[2024-01-28T12:20:47.005+0100] {spark_submit.py:571} INFO - 24/01/28 12:20:47 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-28T12:20:48.015+0100] {spark_submit.py:571} INFO - 24/01/28 12:20:48 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-28T12:20:49.027+0100] {spark_submit.py:571} INFO - 24/01/28 12:20:49 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-28T12:20:50.029+0100] {spark_submit.py:571} INFO - 24/01/28 12:20:50 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-28T12:20:51.030+0100] {spark_submit.py:571} INFO - 24/01/28 12:20:51 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-28T12:20:52.045+0100] {spark_submit.py:571} INFO - 24/01/28 12:20:52 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-28T12:20:53.046+0100] {spark_submit.py:571} INFO - 24/01/28 12:20:53 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-28T12:20:54.058+0100] {spark_submit.py:571} INFO - 24/01/28 12:20:54 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-28T12:20:55.063+0100] {spark_submit.py:571} INFO - 24/01/28 12:20:55 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-28T12:20:56.070+0100] {spark_submit.py:571} INFO - 24/01/28 12:20:56 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-28T12:20:56.073+0100] {spark_submit.py:571} INFO - 24/01/28 12:20:56 INFO RetryInvocationHandler: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking ApplicationClientProtocolPBClientImpl.getNewApplication over null after 8 failover attempts. Trying to failover after sleeping for 33949ms.
[2024-01-28T12:21:31.049+0100] {spark_submit.py:571} INFO - 24/01/28 12:21:31 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-28T12:21:32.051+0100] {spark_submit.py:571} INFO - 24/01/28 12:21:32 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-28T12:21:33.077+0100] {spark_submit.py:571} INFO - 24/01/28 12:21:33 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-28T12:21:34.095+0100] {spark_submit.py:571} INFO - 24/01/28 12:21:34 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-28T12:21:35.107+0100] {spark_submit.py:571} INFO - 24/01/28 12:21:35 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-28T12:21:36.117+0100] {spark_submit.py:571} INFO - 24/01/28 12:21:36 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-28T12:21:37.130+0100] {spark_submit.py:571} INFO - 24/01/28 12:21:37 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-28T12:21:38.131+0100] {spark_submit.py:571} INFO - 24/01/28 12:21:38 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-28T12:21:39.135+0100] {spark_submit.py:571} INFO - 24/01/28 12:21:39 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-28T12:21:40.215+0100] {spark_submit.py:571} INFO - 24/01/28 12:21:40 INFO Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2024-01-28T12:21:40.235+0100] {spark_submit.py:571} INFO - 24/01/28 12:21:40 INFO RetryInvocationHandler: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking ApplicationClientProtocolPBClientImpl.getNewApplication over null after 9 failover attempts. Trying to failover after sleeping for 20943ms.
[2024-01-28T12:21:55.242+0100] {local_task_job_runner.py:302} WARNING - State of this instance has been externally set to failed. Terminating instance.
[2024-01-28T12:21:56.417+0100] {process_utils.py:131} INFO - Sending Signals.SIGTERM to group 22894. PIDs of all processes in the group: [22895, 22894]
[2024-01-28T12:21:56.420+0100] {process_utils.py:86} INFO - Sending the signal Signals.SIGTERM to group 22894
[2024-01-28T12:21:56.430+0100] {taskinstance.py:2451} ERROR - Received SIGTERM. Terminating subprocesses.
[2024-01-28T12:21:56.443+0100] {spark_submit.py:697} INFO - Sending kill signal to spark-submit
[2024-01-28T12:21:58.823+0100] {process_utils.py:79} INFO - Process psutil.Process(pid=22895, status='terminated', started='12:04:32') (22895) terminated with exit code None
[2024-01-28T12:21:58.862+0100] {process_utils.py:79} INFO - Process psutil.Process(pid=22894, status='terminated', exitcode=0, started='12:04:31') (22894) terminated with exit code 0
